{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNffTUIWG1YztPoN27lKfyJ"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Llama3 70b Data Generalization**"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "91pgfD2gwRie",
    "ExecuteTime": {
     "end_time": "2025-08-13T08:25:40.265201Z",
     "start_time": "2025-08-13T08:25:35.922607Z"
    }
   },
   "source": [
    "import ast\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import API_TOKEN"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configure prompt"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T08:25:46.781275Z",
     "start_time": "2025-08-13T08:25:46.774271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_output(id_note: int, output_split: list) -> dict:\n",
    "\n",
    "    anonym_text = output_split[1]\n",
    "    obscured_entities = output_split[3].split(',')\n",
    "\n",
    "    # Remove [\n",
    "    if obscured_entities[0].strip().startswith('['):\n",
    "        obscured_entities[0] = obscured_entities[0].strip()[1:]\n",
    "\n",
    "    # Remove ]\n",
    "    if obscured_entities[-1].strip().endswith(']'):\n",
    "        obscured_entities[-1] = obscured_entities[-1].strip()[:-1]\n",
    "\n",
    "    data = {\n",
    "        \"id_note\": id_note,\n",
    "        \"anonym_text\": anonym_text,\n",
    "        \"obscured_entities\": set(obscured_entities)\n",
    "    }\n",
    "\n",
    "    # Remove ' '\n",
    "    data['anonym_text'] = data['anonym_text'].lstrip()\n",
    "\n",
    "    # Remove ' '\n",
    "    data['obscured_entities'] = {entity.lstrip() for entity in data['obscured_entities']}\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T08:25:48.280514Z",
     "start_time": "2025-08-13T08:25:48.274367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create prompt for evaluating note.\n",
    "def create_prompt(note: str) -> str:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are an AI assistant specialized in anonymizing sensitive medical information according to GDPR regulations, with specific attention to Articles 4 and 9.  Your task is to anonymize the provided medical note by applying Data Generalization techniques: replace any identifiable or sensitive details with broader, non-identifiable categories.\n",
    "\n",
    "        The sensitive entities to be anonymized are:\n",
    "        - Patient's age, name, and gender\n",
    "        - Psychiatric diagnoses and detailed clinical history\n",
    "        - Specific pharmacological therapies (e.g., olanzapine, trihexyphenidyl) and their dosages\n",
    "        - Side effects and neurological/motor symptoms\n",
    "        - Functional data and personal autonomy details\n",
    "        - Detailed clinical and therapeutic timelines\n",
    "\n",
    "        Given the following original medical text:\n",
    "        \\\"\\\"\\\"{note}\\\"\\\"\\\"\n",
    "\n",
    "        Your output must be formatted as follows:\n",
    "\n",
    "        Anonymized Text:\n",
    "        [Anonymized version of the note]\n",
    "\n",
    "        Obscured Entities from Original Medical Text:\n",
    "        [original sensitive entity 1, original sensitive entity 2, ...]\n",
    "\n",
    "        Do not explain or comment on the output.\n",
    "        \"\"\"\n",
    "    return prompt"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reading sample masked dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T08:25:54.906975Z",
     "start_time": "2025-08-13T08:25:54.020585Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"../../datasets/sample/masked_dataset_sample.csv\")",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T09:24:26.247372Z",
     "start_time": "2025-08-12T09:24:26.239373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_inference():\n",
    "    csv_path = \"../../datasets/sample/llama3_data_generalization.csv\"\n",
    "\n",
    "    # Indexes already processed\n",
    "    if os.path.exists(csv_path):\n",
    "        existing_df = pd.read_csv(csv_path)\n",
    "        processed_indices = set(existing_df['index'].tolist())\n",
    "    else:\n",
    "        processed_indices = set()\n",
    "\n",
    "    for i in tqdm(range(0, len(df)), desc=\"Llama3 Requests\"):\n",
    "        index = int(df['index'][i])\n",
    "        if index in processed_indices:\n",
    "            continue  # salta riga gi√† processata\n",
    "\n",
    "        client = OpenAI(api_key=API_TOKEN, base_url=\"https://api.gpt4-all.xyz/v1\")\n",
    "        note = df['note'][i]\n",
    "        prompt = create_prompt(note=note)\n",
    "\n",
    "        try:\n",
    "            api_response = client.chat.completions.create(\n",
    "                model=\"llama-3.3-70b\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "                top_p=0.95,\n",
    "                stream=False,\n",
    "            )\n",
    "\n",
    "            output = api_response.choices[0].message.content\n",
    "            output_split = output.split('\\n')\n",
    "            if '' in output_split:\n",
    "                output_split.remove('')\n",
    "\n",
    "            formatted_data = process_output(id_note=index, output_split=output_split)\n",
    "            anonym_note = formatted_data['anonym_text']\n",
    "            sensitive_entity_note = formatted_data['obscured_entities']\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            anonym_note = ''\n",
    "            sensitive_entity_note = ''\n",
    "\n",
    "        # Create row\n",
    "        new_row = {\n",
    "            'index': index,\n",
    "            'note': note,\n",
    "            'anonym_note': anonym_note,\n",
    "            'sensitive_entity_note': sensitive_entity_note\n",
    "        }\n",
    "\n",
    "        new_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Write on file csv\n",
    "        if os.path.exists(csv_path):\n",
    "            new_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            new_df.to_csv(csv_path, index=False)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "make_inference()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
